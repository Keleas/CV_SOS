{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция №4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Thresholding\n",
    "Здесь все просто. Если значение пикселя больше порогового значения, ему присваивается одно значение (может быть белым), в противном случае ему присваивается другое значение (может быть черным). Используемая функция **cv2.threshold(src, thresh, maxval, type)**\n",
    "\n",
    "* **src** $-$ исходное изображение, которое должно быть изображением в градациях серого\n",
    "* **thresh** $-$ пороговое значение, которое используется для классификации значений пикселей\n",
    "* **maxval** $-$ представляет значение, которое будет дано, если значение пикселя больше (иногда меньше) порогового значения\n",
    "* **type** $-$ предоставляет различные стили порогового значения.\n",
    "\n",
    "Различные типы:\n",
    "1. cv2.THRESH_BINARY\n",
    "2. cv2.THRESH_BINARY_INV\n",
    "3. cv2.THRESH_TRUNC\n",
    "4. cv2.THRESH_TOZERO\n",
    "5. cv2.THRESH_TOZERO_INV\n",
    "\n",
    "На выходе функция возвращает два значения. Первый $-$ **retval**, которое будет объяснено позже. Второй $-$ **thresholded image**.\n",
    "\n",
    "Подробнее в [документации](https://docs.opencv.org/3.4.2/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57).\n",
    "\n",
    "Рассмотрим разные типы threshold на примере градиента серого цвета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:31:10.292653Z",
     "start_time": "2019-07-16T20:31:09.243459Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:31:19.044254Z",
     "start_time": "2019-07-16T20:31:18.453619Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('../img/grad_grayscale.png',0)\n",
    "\n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "plt.figure(figsize=(10,8))\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Thresholding\n",
    "В предыдущем разделе мы использовали глобальное значение в качестве порогового значения. Но это может быть не хорошо во всех условиях, когда изображение имеет разные условия освещения в разных областях. В этом случае мы идем на адаптивный порог. При этом алгоритм вычисляет порог для небольших областей изображения. Таким образом, мы получаем разные пороговые значения для разных областей одного и того же изображения, и это дает нам лучшие результаты для изображений с разной освещенностью.\n",
    "\n",
    "Он имеет три «специальных» входных параметра и только один выходной аргумент.\n",
    "\n",
    "Адаптивный метод $-$ **cv2.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C)** - решает, как рассчитывается пороговое значение.\n",
    "\n",
    "* **thresholdType**:\n",
    "    * *cv2.ADAPTIVE_THRESH_MEAN_C*: пороговое значение является средним значением области соседства.\n",
    "\n",
    "    * *cv2.ADAPTIVE_THRESH_GAUSSIAN_C*: пороговое значение представляет собой взвешенную сумму значений окрестностей, где веса представляют собой гауссово окно.\n",
    "\n",
    "* **blockSize** $-$ определяет размер окна.\n",
    "\n",
    "* **C** $-$ это константа, которая вычитается из вычисленного среднего или взвешенного среднего.\n",
    "\n",
    "Ниже приведен фрагмент кода, сравнивающий глобальные пороги и адаптивные пороги для изображения с различным освещением:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:31:26.176823Z",
     "start_time": "2019-07-16T20:31:25.805371Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('../img/sudoku.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "img = cv2.medianBlur(img,5)\n",
    "ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "images = [img, th1, th2, th3]\n",
    "plt.figure(figsize=(10,8))\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бинаризация Оцу\n",
    "В первом разделе я говорил вам, что есть второй параметр retVal. Его использование происходит, когда мы идем на бинаризацию Оцу. Так что же это?\n",
    "\n",
    "В глобальном пороговом значении мы использовали произвольное значение для порогового значения, верно? Итак, как мы можем знать, что выбранное нами значение является хорошим или нет? Ответ, метод проб и ошибок. Но рассмотрим бимодальное изображение (проще говоря, бимодальное изображение - это изображение, гистограмма которого имеет два пика). Для этого изображения мы можем приблизительно принять значение в середине этих пиков в качестве порогового значения, верно? Это то, что делает бинаризация Оцу. Таким образом, простыми словами, он автоматически вычисляет пороговое значение из гистограммы изображения для бимодального изображения. (Для изображений, которые не являются бимодальными, бинаризация не будет точной.)\n",
    "\n",
    "Для этого используется наша функция **cv2.threshold()**, но передается дополнительный флаг *cv2.THRESH_OTSU*. Для порогового значения просто введите ноль. Затем алгоритм находит оптимальное пороговое значение и возвращает вас в качестве второго выхода retVal. Если пороговое значение Otsu не используется, **retVal** соответствует пороговому значению, которое вы использовали.\n",
    "\n",
    "Проверьте ниже пример. Входное изображение является шумным изображением. В первом случае я применил глобальный порог для значения $127$. Во втором случае я применил порог Оцу напрямую. В третьем случае я отфильтровал изображение с гауссовым ядром $5\\times5$, чтобы удалить шум, затем применил пороговое значение Оцу. Посмотрите, как фильтрация шума улучшает результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:31:37.488310Z",
     "start_time": "2019-07-16T20:31:31.657699Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('../img/laba.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "noise_img = img.copy()\n",
    "mask = np.random.randint(0,2,size=noise_img.shape).astype(np.bool)\n",
    "r = np.random.rand(*noise_img.shape)*np.max(noise_img)\n",
    "noise_img[mask] = r[mask]\n",
    "\n",
    "img = noise_img\n",
    "\n",
    "\n",
    "# global thresholding\n",
    "ret1,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "# Otsu's thresholding\n",
    "ret2,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "# plot all the images and their histograms\n",
    "images = [img, 0, th1,\n",
    "          img, 0, th2,\n",
    "          blur, 0, th3]\n",
    "titles = ['Original Noisy Image','Histogram','Global Thresholding (v=127)',\n",
    "          'Original Noisy Image','Histogram',\"Otsu's Thresholding\",\n",
    "          'Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\n",
    "plt.figure(figsize=(14,10))\n",
    "for i in range(3):\n",
    "    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')\n",
    "    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)\n",
    "    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')\n",
    "    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Производная\n",
    "\n",
    "На прошлом лекции, мы рассмотрели операцию свёртки и отметили, что свёртка — это очень полезная и распространённая операция, лежащая в основе различных фильтров. \n",
    "\n",
    "Одна из важнейших свёрток $-$ это вычисление производных. \n",
    "В математике и физике производные играют очень важную роль, то же самое можно сказать и про компьютерное зрение.\n",
    "Но что же это за производная от изображения? Как мы помним, изображения, с которыми мы работаем, состоят из пикселей, которые, для картинки в градациях серого, задают значение яркости.\n",
    "Т.е. наша картинка $-$ это просто двумерная матрица чисел. Теперь вспомним, что же такое производная.\n",
    "***\n",
    "**Производная (функции в точке)** $-$ это скорость изменения функции (в данной точке). Определяется как предел отношения приращения функции к приращению ее аргумента при стремлении приращения аргумента к нулю.\n",
    "***\n",
    "\n",
    "Получается, что, в нашем случае, производная — это отношение значения приращения пикселя по y к значению приращению пикселя по x: $dI = \\frac{dy}{dx}$\n",
    "\n",
    "Работая с изображением I, мы работает с функцией двух переменных $I(x,y)$, т.е. со скалярным полем. Поэтому, более правильно говорить не о производной, а о градиенте изображения.\n",
    "***\n",
    "**Градиент (от лат. gradiens — шагающий, растущий)** $-$ вектор, показывающий направление наискорейшего возрастания некоторой величины, значение которой меняется от одной точки пространства к другой (скалярного поля).\n",
    "***\n",
    "\n",
    "Если каждой точке M области многомерного пространства поставлено в соответствие некоторое (обычно $-$ действительное) число $u$, то говорят, что в этой области задано скалярное поле.\n",
    "\n",
    "\n",
    "Итак, градиент для каждой точки изображения (функция яркости) — двумерный вектор, компонентами которого являются производные яркости изображения по горизонтали и вертикали $-$ $grad[I(x,y)] = (\\frac{dI}{dx}, \\frac{dI}{dy})$\n",
    "\n",
    "В каждой точке изображения градиентный вектор ориентирован в направлении наибольшего увеличения яркости, а его длина соответствует величине изменения яркости.\n",
    "\n",
    "вектор (в заданной точке) задаётся двумя значениями: длиной и направлением.\n",
    "\n",
    "* длинной: $\\sqrt{dx^2 + dy^2}$;\n",
    "\n",
    "* направление $-$ угол между вектором и осью $x$: $\\tan^{-1}(\\frac{dy}{dx})$;\n",
    "\n",
    "\n",
    "Для дифференцирования изображения используется, так называемый, оператор **Собеля**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оператор Собеля** $-$ это дискретный дифференциальный оператор, вычисляющий приближение градиента яркости изображения.\n",
    "Оператор вычисляет градиент яркости изображения в каждой точке. Так находится направление наибольшего увеличения яркости и величина её изменения в этом направлении. Результат показывает, насколько «резко» или «плавно» меняется яркость изображения в каждой точке, а значит, вероятность нахождения точки на грани, а также ориентацию границы.\n",
    "\n",
    "Т.о. результатом работы оператора Собеля в точке области постоянной яркости будет нулевой вектор, а в точке, лежащей на границе областей различной яркости — вектор, пересекающий границу в направлении увеличения яркости.\n",
    "\n",
    "Наиболее часто оператор Собеля применяется в алгоритмах выделения границ. \n",
    "\n",
    "Оператор Собеля основан на свёртке изображения небольшими целочисленными фильтрами в вертикальном и горизонтальном направлениях, поэтому его относительно легко вычислять. Оператор использует ядра 3x3, с которыми свёртывают исходное изображение для вычисления приближенных значений производных по горизонтали и по вертикали.\n",
    "\n",
    "\n",
    "### Формализация\n",
    "Пусть ${\\displaystyle \\mathbf {A} }$ $-$ это исходное изображение, а ${\\displaystyle \\mathbf {G} _{x}}$ и ${\\displaystyle \\mathbf {G} _{y}}$ $-$ два изображения, на которых каждая точка содержит приближённые производные по ${\\displaystyle x}$ и по ${\\displaystyle y}$. Они вычисляются следующим образом:\n",
    "\n",
    "${\\displaystyle \\mathbf {G} _{y}={\\begin{bmatrix}-1&-2&-1\\\\0&0&0\\\\+1&+2&+1\\\\\\end{bmatrix}}*\\mathbf {A} \\quad {\\mbox{and}}\\quad \\mathbf {G} _{x}={\\begin{bmatrix}-1&0&+1\\\\-2&0&+2\\\\-1&0&+1\\end{bmatrix}}*\\mathbf {A} }$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Контур и как его найти"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Контурный анализ** $-$ это один из важных и очень полезных методов описания, хранения, распознавания, сравнения и поиска графических образов/объектов. \n",
    "\n",
    "**Контур** $-$ это внешние очертания (обвод) предмета/объекта.\n",
    "\n",
    "При проведении контурного анализа:\n",
    "* полагается, что контур содержит достаточную информацию о форме объекта;\n",
    "* внутренние точки объекта во внимание не принимаются. \n",
    "\n",
    "Вышеприведённые положения, разумеется, накладывают существенные ограничения на область применения контурного анализа, которые, в основном, связаны с проблемами выделения контура на изображениях:\n",
    "* из-за одинаковой яркости с фоном объект может не иметь чёткой границы, или может быть зашумлён помехами, что приводит к невозможности выделения контура;\n",
    "* перекрытие объектов или их группировка приводит к тому, что контур выделяется неправильно и не соответствует границе объекта.\n",
    "\n",
    "Однако, переход к рассмотрению только контуров объектов позволяет уйти от пространства изображения – к пространству контуров, что существенно снижает сложность алгоритмов и вычислений. \n",
    "\n",
    "Т.о., контурный анализ имеет довольно слабую устойчивость к помехам, и любое пересечение или лишь частичная видимость объекта приводит либо к невозможности детектирования, либо к ложным срабатываниям, но простота и быстродействие контурного анализа, позволяют вполне успешно применять данный подход (при чётко выраженном объекте на контрастном фоне и отсутствии помех).\n",
    "\n",
    "Итак, мы определились, что контур — это некая граница объекта, которая отделяет его от фона (других объектов). \n",
    "\n",
    "Во всех случаях мы получаем бинарное изображение, которое явным образом задаёт нам границы объекта. Вот эта совокупность пикселей, составляющих границу объекта и есть контур объекта.\n",
    "\n",
    "Чтобы оперировать полученным контуром, его необходимо как-то представить (закодировать). \n",
    "Например, указывать вершины отрезков, составляющих контур.\n",
    "Другой известный способ кодирования контура $-$ это **цепной код Фримена**. Этот метод будет рассмотрен чуть позже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оператор Лапласа\n",
    "Он вычисляет лапласиан изображения, заданного соотношением,\n",
    "${\\Delta src = \\frac{\\partial ^2{src}}{\\partial x^2} + \\frac{\\partial ^2{src}}{\\partial y^2}}$\n",
    "где каждая производная находится с использованием производных Собеля. Если ksize = $1$, то для фильтрации используется следующее ядро:\n",
    "\n",
    "$$\n",
    "{K = \\begin{pmatrix}\n",
    "0 & \\ 1 & \\ 0 \\\\ \n",
    "1 & \\ -4 & \\ 1 \\\\ \n",
    "0 & \\ 1 & \\ 0 \n",
    "\\end{pmatrix}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:31:53.364183Z",
     "start_time": "2019-07-16T20:31:52.610814Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('../img/road_2.jpg')\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "## выделяем границы\n",
    "laplac = cv2.Laplacian(gray_img, cv2.THRESH_BINARY, scale=0.25, ksize=5)\n",
    "laplac = cv2.medianBlur(laplac, 5)\n",
    "\n",
    "fig, m_axs = plt.subplots(1,2, figsize=(14,12))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('gray')\n",
    "ax1.imshow(gray_img, cmap='gray')\n",
    "ax2.set_title('laplaccian')\n",
    "ax2.imshow(laplac, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Детектор границ Кенни (Canny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория\n",
    "**Canny Edge Detection** $-$ популярный алгоритм обнаружения краев. Это многоступенчатый алгоритм, и мы пройдем через все этапы.\n",
    "\n",
    "1. **Шумоподавление**\n",
    "\n",
    "Поскольку обнаружение краев подвержено воздействию шума на изображении, первым шагом является удаление шума на изображении с помощью фильтра Гаусса $5\\times5$. Мы уже видели это в предыдущих главах.\n",
    "\n",
    "2. **Поиск градиента интенсивности изображения**\n",
    "\n",
    "Затем сглаженное изображение фильтруется ядром Собеля (рассмотрен выше) в горизонтальном и вертикальном направлении, чтобы получить первую производную в горизонтальном направлении ($G_x$) и вертикальном направлении ($G_y$). Из этих двух изображений мы можем найти градиент края и направление для каждого пикселя следующим образом:\n",
    "\n",
    "$${Edge(G) = \\sqrt{ G_x^2 + G_y^2}}$$\n",
    "$${Angle(\\theta) = \\tan^{-1}(\\frac{G_x}{G_y})}$$\n",
    "\n",
    "Направление градиента всегда перпендикулярно краям. Он округлен до одного из четырех углов, представляющих вертикальное, горизонтальное и два диагональных направления.\n",
    "\n",
    "3. **Немаксимальное подавление**\n",
    "\n",
    "После получения величины и направления градиента выполняется полное сканирование изображения для удаления любых нежелательных пикселей, которые могут не составлять края. Для этого в каждом пикселе пиксель проверяется, является ли он локальным максимумом в его окрестности в направлении градиента. Проверьте изображение ниже:\n",
    "\n",
    "<img src=\"../img/nms.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/> \n",
    "\n",
    "Точка $А$ находится на краю (в вертикальном направлении). Направление градиента нормальное к краю. Точки $B$ и $C$ находятся в градиентных направлениях. Таким образом, точка $A$ проверяется с помощью точек $B$ и $C$, чтобы увидеть, образует ли она локальный максимум. Если это так, он рассматривается для следующего этапа, в противном случае он подавляется (обнуляется).\n",
    "\n",
    "Короче говоря, в результате вы получите бинарное изображение с «тонкими краями».\n",
    "\n",
    "4. **Гистерезис пороговый**\n",
    "\n",
    "Эта стадия решает, какие ребра действительно являются ребрами, а какие нет. Для этого нам понадобятся два пороговых значения, **minVal** и **maxVal**. Любые ребра с градиентом интенсивности, превышающим **maxVal**, обязательно будут ребрами, а ребра ниже **minVal** не будут ребрами, поэтому отбрасываются. Те, кто лежит между этими двумя порогами, классифицируются как ребра или не ребра в зависимости от их связности. Если они связаны с точными пикселями, они считаются частью ребер. В противном случае они также отбрасываются. Смотрите изображение ниже:\n",
    "\n",
    "<img src=\"../img/hysteresis.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/> \n",
    "\n",
    "Край $A$ выше **maxVal**, так что считается «верным краем». Хотя ребро $C$ меньше **maxVal**, оно связано с ребром $A$, так что это также считается допустимым ребром, и мы получаем эту полную кривую. Но ребро $B$, хотя оно выше **minVal** и находится в той же области, что и ребро $C$, не связано с каким-либо «верным краем», поэтому отбрасывается. Поэтому очень важно, чтобы мы выбрали соответственно **minVal** и **maxVal**, чтобы получить правильный результат.\n",
    "\n",
    "На этом этапе также удаляются небольшие пиксельные шумы в предположении, что края являются длинными линиями.\n",
    "\n",
    "Итак, что мы в итоге получаем, это сильные края изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Детектор границ Кенни в OpenCV\n",
    "OpenCV помещает все вышеперечисленное в одну функцию **cv2.Canny(image,threshold1,threshold2,apertureSize,L2gradient)**. \n",
    "\n",
    "* **image** $-$ это наше входное изображение\n",
    "* **threshold1** $-$ minVal для процедуры гистерезиса\n",
    "* **threshold2** $-$ maxVal для процедуры гистерезиса\n",
    "* **apertureSize** $-$ размер ядра Собеля, используемый для поиска градиентов изображения, по умолчанию равен $3$\n",
    "* **L2gradient** $-$ флаг, определяет уравнение для определения величины градиента. Если это True, он использует упомянутое выше уравнение, которое является более точным, в противном случае он использует эту функцию: Edge_Gradient($G$) = |$G_x$| + |$G_y$|. По умолчанию это False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:32:02.233842Z",
     "start_time": "2019-07-16T20:32:01.554873Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('../img/road_2.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "#sobel = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)\n",
    "edges = cv2.Canny(img,360,360,5)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Original Image')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Edge Image')\n",
    "ax2.imshow(edges, cmap='gray');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Контрольные вопросы:__\n",
    "\n",
    "В чем минусы сразу брать границы у такого изображения?\n",
    "\n",
    "Можно настроить параметы алгоритма так, чтобы выделить здание?\n",
    "\n",
    "Что нужно исправить с картинкой?\n",
    "\n",
    "Какое концептуальное различие в приминении размытия и морфологии к обработке картинки с контуром?\n",
    "***\n",
    "Почему это работает плохо тут?\n",
    "Где будет работать хорошо? Зачем это нужно? (выделения полосы движения на дороге, локальные задачи поиска предметов)\n",
    "\n",
    "Выделить цвет, который характерен для исследуемого объекта, затем применить поиск границ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Самостоятельная работа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваша задача попробовать на практике методы, которые мы изучили на лекциях к любой картинке из примеров к данной работе. \n",
    "\n",
    "**Основная цель** $-$ вытащить из изображения его границы, для дальнейший работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ниже приведен пример кода:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:32:08.507375Z",
     "start_time": "2019-07-16T20:32:06.963229Z"
    }
   },
   "outputs": [],
   "source": [
    "## сюда же морфологию еще прикрутить\n",
    "     \n",
    "img = cv2.imread('../img/laba.jpg')\n",
    "img = cv2.resize(img.copy(), (600, 400))\n",
    "## для отрисовки в pyplot\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    \n",
    "## Лапласиан \n",
    "kernel = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=np.float32)/0.1\n",
    "\n",
    "## переведем изображение в оттенки серого - цвет нам тут не нужен\n",
    "gray = cv2.cvtColor(img.copy(), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "## Попробуем несколько типов блюра \n",
    "blur = cv2.blur(gray, (3,3))                       ## осреднение значений в ядре \n",
    "gaus_blur = cv2.GaussianBlur(gray, (5,5), 0)       ## гауссов блюр \n",
    "median_blur = cv2.medianBlur(gray, 5)              ## медиана всех значений в ядре \n",
    "bil_blur = cv2.bilateralFilter(gray, 9, 75, 75)    ## двусторонниый фильтр \n",
    "pyr_d = cv2.pyrDown(gray)                          ## blur & downsampling\n",
    "pyr_u = cv2.pyrUp(gray)                            ## blur & upsampling \n",
    "#pyr_mean = cv2.pyrMeanShiftFiltering(img, 25, 40)  ## выделяет области по цвету (аналог knn в машинке)\n",
    "\n",
    "#gray_pyr_mean = cv2.cvtColor(pyr_mean, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "## Применяем фильтры \n",
    "dst = cv2.filter2D(pyr_u, -1, kernel)           ## находим границы лапласианом\n",
    "#dst_blur = cv2.GaussianBlur(dst, (5,5),0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "dst_blur = cv2.bilateralFilter(dst,9,75,75)                  ## еще раз блюрим для гладких границ \n",
    "\n",
    "## Визуализация\n",
    "fig, m_axs = plt.subplots(3, 1, figsize=(24, 20))\n",
    "ax1, ax2, ax3 = m_axs\n",
    "\n",
    "plt.gray()\n",
    "ax1.set_title('blur', fontsize=20)\n",
    "ax1.imshow(pyr_u)\n",
    "ax2.set_title('Laplacian', fontsize=20)\n",
    "ax2.imshow(dst)\n",
    "ax3.set_title('Laplacian + Blur', fontsize=20)\n",
    "ax3.imshow(dst_blur);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Еще пример кода:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:32:15.927386Z",
     "start_time": "2019-07-16T20:32:14.842536Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('../img/lk.jpg')\n",
    "## для отрисовки в pyplot\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img = cv2.medianBlur(img, 5)\n",
    "#img = cv2.pyrMeanShiftFiltering(img, 25, 40)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "th1 = cv2.threshold(img, 120, 255, cv2.THRESH_TOZERO)[1]\n",
    "th2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "th3 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 3)\n",
    "\n",
    "## Визуализация\n",
    "fig, m_axs = plt.subplots(3, 1, figsize=(24, 20))\n",
    "ax1, ax2, ax3 = m_axs\n",
    "\n",
    "plt.gray()\n",
    "ax1.set_title('th1', fontsize=20)\n",
    "ax1.imshow(th1)\n",
    "ax2.set_title('th2', fontsize=20)\n",
    "ax2.imshow(th2)\n",
    "ax3.set_title('th3', fontsize=20)\n",
    "ax3.imshow(th3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразования Хафа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория\n",
    "**Hough Transform** $-$ популярный метод обнаружения любой формы, если вы можете представить эту форму в математической форме. Он может обнаружить форму, даже если он немного сломан или искажен. Посмотрим, как это работает для линии.\n",
    "\n",
    "Линия может быть представлена как ${y = mx + c}$ или в параметрической форме, как ${\\rho=x\\cos(\\theta)+y\\sin(\\theta)}$, где ${\\rho}$ $-$ перпендикулярное расстояние от начала координат до линии, а $\\theta$ $-$ угол, образованный этой перпендикулярной линией и горизонтальной осью, измеренный в счетчике по часовой стрелке (это направление зависит от того, как вы представляете систему координат. Это представление используется в OpenCV). Проверьте изображение ниже:\n",
    "\n",
    "IMG\n",
    "\n",
    "Таким образом, если линия проходит ниже начала координат, она будет иметь положительное значение $\\rho$ и $\\theta <180$. Если она идет выше начала координат, вместо того, чтобы брать угол больше $180$, угол выбирается меньше $180$, а значение ${\\rho}$ принимается отрицательным. Любая вертикальная линия будет иметь $0$ градусов, а горизонтальные линии будут иметь $90$ градусов.\n",
    "\n",
    "Теперь посмотрим, как работает Hough Transform для линий. Любая линия может быть представлена в этих двух терминах ${(\\rho, \\theta)}$. Поэтому сначала он создает двумерный массив или аккумулятор (для хранения значений двух параметров), и для него изначально устанавливается значение ${\\theta}$. Пусть строки обозначают ${\\rho}$, а столбцы $-$ ${\\theta}$. Размер массива зависит от точности, которая вам нужна. Предположим, вы хотите, чтобы точность углов составляла 1 градус, вам нужно $180$ столбцов. Для ${\\rho}$ максимально возможное расстояние $-$ это диагональная длина изображения. Таким образом, с точностью до одного пикселя, количество строк может быть диагональной длины изображения.\n",
    "\n",
    "Рассмотрим изображение размером $100\\times100$ с горизонтальной линией посередине. Возьмите первую точку линии. Вы знаете его $(x,y)$ значения. Теперь в линейном уравнении поместите значения ${\\theta = 0,1,2, \\dots, 180}$ и проверьте полученное значение ${\\rho}$. Для каждой ${(\\rho, \\theta)}$ пары вы увеличиваете значение на единицу в нашем аккумуляторе в соответствующих ${(\\rho, \\theta)}$ ячейках. Так что теперь в аккумуляторе ячейка $(50,90) = 1$ вместе с некоторыми другими ячейками.\n",
    "\n",
    "Теперь возьмите вторую точку на линии. Сделайте так же, как указано выше. Увеличьте значения в ячейках, соответствующих ${(\\rho, \\theta)}$, которые вы получили. На этот раз ячейка $(50,90) = 2$. На самом деле вы голосуете за значения ${(\\rho, \\theta)}$. Вы продолжаете этот процесс для каждой точки на линии. В каждой точке ячейка $(50,90)$ будет увеличена или оценена, в то время как другие ячейки могут или не могут быть проголосованы. Таким образом, в конце ячейка $(50,90)$ получит максимальное количество голосов. Поэтому, если вы будете искать в аккумуляторе максимальное количество голосов, вы получите значение $(50,90)$, которое говорит, что на этом изображении есть линия на расстоянии $50$ от начала координат и под углом $90$ градусов. Это хорошо показано на анимации ниже:\n",
    "\n",
    "<img src=\"../img/houghlinesdemo.gif\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ***\n",
    " Более подробное описание алгоритма по [ссылке]( http://homepages.inf.ed.ac.uk/rbf/HIPR2/hough.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование Хафа в OpenCV\n",
    "Все объясненное выше инкапсулировано в функцию OpenCV, **cv2.HoughLines(image,rho,theta,threshold,args*)**. Он просто возвращает массив значений ${(\\rho, \\theta)}$. ${\\rho}$ измеряется в пикселях, а ${\\theta}$ измеряется в радианах.\n",
    "\n",
    "* **image** $-$ «входное изображение», должен быть двоичным изображением, поэтому примените пороговое значение или используйте обнаружение контуров, прежде чем находить применение грубого преобразования\n",
    "* **rho** $-$ разрешение по расстоянию аккумулятора в пикселях\n",
    "* **theta** $-$ угловое разрешение аккумулятора в радианах.\n",
    "* **threshold** $-$ это порог, который означает минимальное количество голосов, которое он должен получить, чтобы его считали линией. Помните, что количество голосов зависит от количества точек на линии. Таким образом, он представляет минимальную длину линии, которая должна быть обнаружена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:32:22.959246Z",
     "start_time": "2019-07-16T20:32:22.363762Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('../img/road_2.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 350, 450, apertureSize=3)\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=150, maxLineGap=10)\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(255,0,0),10)\n",
    "    \n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вероятностное преобразование Хафа\n",
    "В грубом преобразовании вы можете видеть, что даже для строки с двумя аргументами требуется много вычислений. Вероятностное преобразование Хафа - это оптимизация преобразования Хафа, которое мы видели. Он не учитывает все точки, а только случайное подмножество точек, и этого достаточно для обнаружения линии. Просто мы должны уменьшить порог. Смотрите изображение ниже, которое сравнивает Hough Transform и Вероятностное Hough Transform в пространстве Hough.\n",
    "\n",
    "Реализация в OpenCV  **cv2.HoughLinesP(image,rho,theta,threshold,minLineLength,maxLineGap)**. У него есть два новых аргумента.\n",
    "\n",
    "* **minLineLength** $-$ минимальная длина линии. Сегменты линии короче этого отклоняются.\n",
    "* **maxLineGap** $-$ максимально допустимый разрыв между отрезками, чтобы рассматривать их как одну линию.\n",
    "\n",
    "Лучше всего то, что он напрямую возвращает две конечные точки линий. В предыдущем случае вы получили только параметры линий, и вам нужно было найти все точки. Здесь все прямое и простое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-16T20:32:27.493643Z",
     "start_time": "2019-07-16T20:32:26.945169Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('../img/road_2.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 350, 450, apertureSize=3)\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=150, maxLineGap=10)\n",
    "for line in lines:\n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(255,0,0),10)\n",
    "    \n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашняя работа №3\n",
    "\n",
    "[Форма](https://forms.gle/oNLR6oQrSKGMHnhA6) для отправки решения.\n",
    "\n",
    "__ДЕДЛАЙНЫ__:\n",
    "\n",
    "Задача №1 - 21 июля 23:59\n",
    "\n",
    "Укажите в названии файла: \n",
    "1. имя и фамилия\n",
    "2. номер домашки\n",
    "3. номер задания\n",
    "\n",
    "(NAME_LES_TASK.ipynb)\n",
    "\n",
    "В продолжении темы предыдущей задачи. Допустим, нам удалось понять, что на рассматриваемом изображении находится море. Значит, есть шанс на то, что можно найти корабли на картинке. \n",
    "\n",
    "Ваша задача - написать программу, которая посчитает площадь одного или нескольких кораблей на входном изображении. Площадь найти в пикселях. В приложении можно найти реальные спутниковые снимки кораблей. Подобные примеры изображений присутствуют в тесте.\n",
    "\n",
    "<table><tr>\n",
    "    <td> <img src=\"bin_ship/task_img/test_image_01.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
    "    <td> <img src=\"bin_ship/task_img/test_image_06.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
    "    <td> <img src=\"bin_ship/task_img/test_image_08.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
