{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция №3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Свертки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основы сверток\n",
    "**Свертки** $-$ это метод общей обработки сигналов. Люди, изучающие электронику, скажут вам о почти бесконечных бессонных ночах, которые были потрачены на их постижение. На эту тему написано множество книг. Но для компьютерного зрения мы просто разберемся с некоторыми простыми вещами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение\n",
    "Во-первых, давайте посмотрим на математическое определение свертки в дискретной области времени. Позже мы пройдемся по тому, что говорит нам это уравнение.\n",
    "$${\\begin{align}y[n]&=x[n]*h[n]=\\sum_{k=-\\infty}^\\infty x[k]\\cdot h[n-k]\\end{align},}$$\n",
    "\n",
    "где:\n",
    "* **x[n]** $-$ входой сигнал;\n",
    "* **h[n]** $-$ импульсный отклик; \n",
    "* **y[n]** $-$ выходной сигнал;\n",
    "* **$*$** $-$ обозначает свертку. \n",
    "\n",
    "Обратите внимание, что мы умножаем слагаемые $x[k]$ на смещенные по времени $h[n]$ и складываем их.\n",
    "Краеугольный камень понимания свертки лежит в основе импульсного отклика и импульсного разложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разложение импульсной функции\n",
    "\n",
    "Чтобы понять смысл свертки, мы собираемся начать с концепции разложения сигналов. Входной сигнал разлагается на простые аддитивные компоненты, и системный отклик входного сигнала приводит к сложению выходных данных этих компонентов, прошедших через систему.\n",
    "\n",
    "В общем, сигнал может быть разложен как взвешенная сумма базовых сигналов. Например, в рядах Фурье любой периодический сигнал (даже прямоугольный импульсный сигнал) может быть представлен суммой функций синуса и косинуса. Но здесь мы используем импульсные (дельта) функции для базовых сигналов, а не синус и косинус.\n",
    "\n",
    "Изучим следующий пример того, как сигнал разлагается на набор импульсных (дельта) функций:\n",
    "<img src=\"../img/conv_img01.png\" alt=\"Drawing\" style=\"width: 200px;\"/> \n",
    "\n",
    "Импульсная функция выглядит так: ${\\delta(n)={\\begin{cases}1, n=0\\\\ 0, n\\ne0 \\end{cases}}}$.  Тогда для данного примера $x[0]$ можно записать в виде ${x[0] = x[0] \\cdot \\delta[n-0] = 2 \\cdot \\delta[n-0]}$. Тогда $x[1]$ будет равен ${x[1] = x[1] \\cdot \\delta[n-1] = 3 \\cdot \\delta[n-1]}$, потому что ${\\delta[n-1]}$ равна $1$ при $n = 1$ и ноль в других случаях. Таким же образом мы можем записать ${x[2] = x[2] \\cdot \\delta[n-2] = 1 \\cdot \\delta[n-2]}$, сдвинув ${\\delta[n]}$ на 2. Следовательно, сигнал $x[n]$ может быть представлен добавлением $3$ сдвинутых и масштабированных импульсных функций.\n",
    "\n",
    "В общем, сигнал может быть записан как сумма масштабированных и сдвинутых дельта-функций:\n",
    "$${\\begin{align}x[n]=\\sum_{k=0}^2 x[k]\\cdot\\delta[n-k]=x[0]\\cdot\\delta[n-0]+x[1]\\cdot\\delta[n-1]+x[2]\\cdot\\delta[n-2]\\end{align}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импульсивный отклик\n",
    "**Импульсный отклик** $-$ это выход системы, являющийся результатом импульсной функции в качестве входа.\n",
    "Именно это обозначается за $h[n]$. Все волшебство именно тут. Для вас это перестанет быть магией на 2-3 курсе инстиута. \n",
    "\n",
    "Существует огромное множество преобразования для импульсного отклика. Мы рассмотрим только конечные формулы без понимания того, как работает математика.\n",
    "\n",
    "<td> <img src=\"../img/conv_img02.png\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Свертка в 2D\n",
    "2D свертка является просто продолжением предыдущей 1D свертки путем свертки как горизонтального, так и вертикального направлений в двухмерной пространственной области. Свертка часто используется для обработки изображений, таких как сглаживание, повышение резкости и обнаружение краев изображений.\n",
    "\n",
    "Импульсная (дельта) функция также находится в двумерном пространстве, поэтому ${\\delta[m,n]={\\begin{cases}1,\\ m=n=0\\\\0,\\ m\\ne0,n\\ne0\\end{cases}}}$. Импульсный отклик в 2D обычно называют **«ядром»** или **«фильтром»** в обработке изображений.\n",
    "\n",
    "<table><tr>\n",
    "    <td> <img src=\"../img/conv2d_delta.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "    <td> <img src=\"../img/conv_img10.png\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "Кроме того, выходные данные линейной и инвариантной по времени системы могут быть записаны путем свертки входного сигнала $x[m,n]$ и импульсной характеристики $h[m,n]$:\n",
    "$${\\begin{align}y[m,n]=x[m,n]*h[m,n]=\\sum_{j=-\\infty}^\\infty \\sum_{i=-\\infty}^\\infty x[i,j]\\cdot h[m-i,n-j]\\end{align}}$$\n",
    "\n",
    "Изучим пример, чтобы уточнить, как работает свертка в **2D**-пространстве.\n",
    "Допустим, что размер импульсного отклика (ядра) составляет $3\\times3$, а его значения **a, b, c, d, ...**\n",
    "\n",
    "Обратите внимание, что начало координат $(0,0)$ находится в центре ядра.\n",
    "\n",
    "Давайте выберем простейший пример и вычислим свертку, например, результат в $(1,1)$:\n",
    "<img src=\"../img/conv_img11.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "$${\\begin{align}\n",
    "y[1,1] & = \\sum_{j=0}^2 \\sum_{i=0}^2 x[i,j] \\cdot h[1-i,1-j]  \\\\ &\n",
    "= x[0,0] \\cdot h[1,1] + x[1,0] \\cdot h[0,1] + x[2,0] \\cdot h[-1,1] \\\\ &\n",
    "+ x[0,1] \\cdot h[1,0] + x[1,1] \\cdot h[0,0] + x[2,1] \\cdot h[-1,0] \\\\ &\n",
    "+ x[0,2] \\cdot h[1,-1] + x[1,2] \\cdot h[0,-1] + x[2,2] \\cdot h[-1,-1]\n",
    "\\end{align}}$$\n",
    "\n",
    "Рассмотрим более конкртеный пример с двумерной сверткой. Предположим, у нас есть входные матрицы $3\\times3$ и ядра $3\\times3$ следующим образом:\n",
    "\n",
    "Input | Kernel | Output\n",
    "-|-|-\n",
    "<img src=\"../img/conv_img15.png\" alt=\"Drawing\" style=\"width: 200px;\"/> | <img src=\"../img/conv_img16.png\" alt=\"Drawing\" style=\"width: 200px;\"/> | <img src=\"../img/conv_img17.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "Выходной сигнал в точке $(1,1)$ для этого примера будет:\n",
    "$${\\begin{align}\n",
    "\\ y[1,1] & = \\sum_{j=0}^2 \\sum_{i=0}^2 x[i,j] \\cdot h[1-i,1-j]  \\\\ &\n",
    "\\ = x[0,0] \\cdot h[1,1] + x[1,0] \\cdot h[0,1] + x[2,0] \\cdot h[-1,1] \\\\ &\n",
    "\\ + x[0,1] \\cdot h[1,0] + x[1,1] \\cdot h[0,0] + x[2,1] \\cdot h[-1,0] \\\\ &\n",
    "\\ + x[0,2] \\cdot h[1,-1] + x[1,2] \\cdot h[0,-1] + x[2,2] \\cdot h[-1,-1] \\\\&\n",
    "\\ = 1 \\cdot 1 + 2 \\cdot 2 + 3 \\cdot 1 \\\\ &\n",
    "\\ + 4 \\cdot 0 + 5 \\cdot 0 + 6 \\cdot 0 \\\\ &\n",
    "\\ + 7 \\cdot (-1) + 8 \\cdot (-2) + 9 \\cdot (-1) \\\\ &\n",
    "\\ = -24 \\\\\n",
    "\\end{align}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Свертки в OpenCV (Фильтрация изображений)\n",
    "\n",
    "Как и в одномерных сигналах, изображения также могут быть отфильтрованы с помощью различных низкочастотных фильтров (LPF), высокочастотных фильтров (HPF) и т.д. \n",
    "**LPF** помогает удалять шумы, размывать изображения. Фильтры **HPF** помогают находить края в изображений.\n",
    "\n",
    "**OpenCV** предоставляет функцию **cv2.filter2D()** для объединения ядра с изображением. В качестве примера мы попробуем усредняющий фильтр на изображении. Ядро усредняющего фильтра $5\\times5$ будет выглядеть так:\n",
    "\n",
    "$${\\begin{equation*}\n",
    "\\ K = \\frac{1}{25} \\begin{pmatrix}\n",
    "1 & \\ 1 & \\ 1 & \\ 1 & \\ 1 \\\\\n",
    "1 & \\ 1 & \\ 1 & \\ 1 & \\ 1 \\\\\n",
    "1 & \\ 1 & \\ 1 & \\ 1 & \\ 1 \\\\\n",
    "1 & \\ 1 & \\ 1 & \\ 1 & \\ 1 \\\\\n",
    "1 & \\ 1 & \\ 1 & \\ 1 & \\ 1 \n",
    "\\end{pmatrix}\n",
    "\\end{equation*}}$$\n",
    "\n",
    "Свертка выполняется согласно теоретическим примерам выше. Как результат мы получаем осредненные пиксели своими 25 соседями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('img/8_ka.jpg')\n",
    "## для отрисовки в pyplot\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5), dtype=np.float32) / 25\n",
    "dst = cv2.filter2D(img.copy(), -1, kernel)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(14, 10))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img)\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(dst);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Размытие изображения (Сглаживание изображения)\n",
    "Размытие изображения достигается путем свертывания изображения с помощью фильтра нижних частот. Это полезно для удаления шумов. Это фактически удаляет высокочастотный контент (например: шум, края) с изображения. Таким образом, края в этой операции немного размыты. (Ну, есть методы размытия, которые тоже не размывают края). **OpenCV** предоставляет в основном четыре типа техники размытия.\n",
    "\n",
    "Более подробное описание реализации фильтров OpenCV есть в [документации](https://docs.opencv.org/3.4.2/d4/d86/group__imgproc__filter.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Усреднение\n",
    "Это делается путем свертки изображения с помощью нормализованного прямоугольного фильтра. Он просто берет среднее значение всех пикселей в области ядра и заменяет центральный элемент. Это выполняется функцией **cv2.blur()** или **cv2.boxFilter()**. Для более подробной информации о ядре посмотрите в документации. Мы должны указать ширину и высоту ядра. Нормализованный блочный фильтр $3\\times3$ будет выглядеть следующим образом:\n",
    "\n",
    "$${\\begin{equation*}K = \\frac{1}{9} \n",
    "{\\begin{pmatrix}\n",
    "1 & \\ 1 & \\ 1 \\\\ \n",
    "1 & \\ 1 & \\ 1 \\\\ \n",
    "1 & \\ 1 & \\ 1 \\end{pmatrix}}\n",
    "\\end{equation*}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv2.blur(img,(3, 3))\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(14, 10))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img)\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(blur);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Размытие по Гауссу\n",
    "При этом вместо box filter используется ядро Гаусса. Это делается с помощью функции **cv2.GaussianBlur()**. Мы должны указать ширину и высоту ядра, которые должны быть положительными и нечетными. Мы также должны указать стандартное отклонение в направлениях **X** и **Y**, **sigmaX** и **sigmaY** соответственно. Если указан только **sigmaX**, то **sigmaY** принимается так же, как **sigmaX**. Если оба даны в виде нулей, они рассчитываются по размеру ядра. Размытие по Гауссу очень эффективно для удаления гауссовского шума с изображения.\n",
    "\n",
    "Если вы хотите, вы можете создать ядро Гаусса с помощью функции **cv2.getGaussianKernel()**, а затем применить его с помощью **cv2.filter2D()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Код для размытия по Гауссу: \n",
    "\n",
    "blur = cv2.GaussianBlur(img,(9,9),0)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(14, 10))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img)\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(blur);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Среднее размытие\n",
    "Здесь функция **cv2.medianBlur()** принимает медиану всех пикселей в области ядра, и центральный элемент заменяется этим медианным значением. Это очень эффективно против шума соли и перца на изображениях. Интересно, что в вышеупомянутых фильтрах центральным элементом является вновь вычисленное значение, которое может быть значением пикселя в изображении или новым значением. Но при медианном размытии центральный элемент всегда заменяется некоторым пиксельным значением на изображении. \n",
    "\n",
    "Эффективно снижает шум. Размер его ядра должен быть положительным нечетным целым числом.\n",
    "\n",
    "В этой демонстрации я добавил шум к нашему исходному изображению и применил медианное размытие. Проверьте результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## внесем шум\n",
    "noise_img = img.copy()\n",
    "mask = np.random.randint(0,2,size=noise_img.shape).astype(np.bool)\n",
    "r = np.random.rand(*noise_img.shape)*np.max(noise_img)\n",
    "noise_img[mask] = r[mask]\n",
    "\n",
    "median = cv2.medianBlur(noise_img, 7)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(14, 10))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(noise_img)\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(median);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Двусторонняя фильтрация\n",
    "\n",
    "**cv2.bilateralFilter()** очень эффективно удаляет шум, сохраняя края острыми. Но операция медленнее по сравнению с другими фильтрами. Мы уже видели, что фильтр Гаусса берет окрестность вокруг пикселя и находит его средневзвешенное значение по Гауссу. Этот гауссов фильтр является функцией только одного пространства, то есть при фильтрации учитываются соседние пиксели. Он не учитывает, имеют ли пиксели почти одинаковую интенсивность. Он не учитывает, является ли пиксель краевым или нет. Таким образом, это стирает края, что мы не хотим делать.\n",
    "\n",
    "Двусторонний фильтр также принимает гауссов фильтр в пространстве, но еще один гауссов фильтр, который является функцией разности пикселей. Гауссова функция пространства обеспечивает размытие только соседних пикселей, а гауссова функция разности интенсивности - размытие только тех пикселей, интенсивность которых равна центральной. Таким образом, он сохраняет края, поскольку пиксели на краях будут сильно изменяться.\n",
    "\n",
    "**Рекомендации к фильтру:**\n",
    "\n",
    "* **Sigma values:** для простоты вы можете установить два значения сигмы одинаковыми. Если они маленькие ($<10$), фильтр не будет иметь большого эффекта, тогда как если они большие ($>150$), они будут иметь очень сильный эффект, делая изображение мультяшным.\n",
    "\n",
    "* **Размер фильтра:** Большие фильтры (d$>5$) очень медленные, поэтому рекомендуется использовать d $=5$ для приложений реального времени и, возможно, d $=9$ для автономных приложений, которые нуждаются в сильной фильтрации шума.\n",
    "\n",
    "Ниже приведены примеры использования двустороннего фильтра:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## внесем шум\n",
    "noise_img = img.copy()\n",
    "mask = np.random.randint(0,2,size=noise_img.shape).astype(np.bool)\n",
    "r = np.random.rand(*noise_img.shape)*np.max(noise_img)\n",
    "noise_img[mask] = r[mask]\n",
    "\n",
    "bilateral = cv2.bilateralFilter(noise_img, d=15, sigmaColor=250, sigmaSpace=250)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(14, 10))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(noise_img)\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(bilateral);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Морфологические трансформации\n",
    "Морфологические преобразования $-$ это простые операции, основанные на форме изображения. Обычно это выполняется на двоичных изображениях. Он требует двух входных данных, один из которых является нашим исходным изображением, второй называется структурирующим элементом или ядром, которое определяет характер операции. Два основных морфологических оператора - это **эрозия** и **растягивание**. Затем его разновидности, такие как открытие, закрытие, градиент и т. д. Мы увидим их воздействие на примере следующего изображения:\n",
    "\n",
    "<img src=\"../img/j.png\" alt=\"Drawing\" style=\"width: 100px;\"/>\n",
    "\n",
    "**Эрозия** (размывание/сужение) изображения обычно используется для избавления от случайных вкраплений на изображении. Идея состоит в том, что вкрапления при размывании устранятся, тогда как крупные и соответсвенно более визуально-значимые регионы остаются.\n",
    "\n",
    "**Растягивание** (расширение) же, по идее, так же должно устранять шум и способствовать объединению областей изображения, которые были разделены шумом, тенями.\n",
    "Применение же небольшого растягивания должно сплавить эти области в одну.\n",
    "\n",
    "Морфологические операции, чаще всего, применяются над двоичными изображениями, которые получаются после порогового преобразования (thresholding).\n",
    "***\n",
    "**Подробнее с математической морфологией можно ознакомиться по этим ссылка: [1](https://ru.wikipedia.org/wiki/%CC%E0%F2%E5%EC%E0%F2%E8%F7%E5%F1%EA%E0%FF_%EC%EE%F0%F4%EE%EB%EE%E3%E8%FF), [2](https://habr.com/post/113626/), [3](http://wiki.technicalvision.ru/index.php/%D0%9C%D0%BE%D1%80%D1%84%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5_%D0%BE%D0%BF%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D0%B8_%D0%BD%D0%B0_%D0%B1%D0%B8%D0%BD%D0%B0%D1%80%D0%BD%D1%8B%D1%85_%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F%D1%85).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Эрозия\n",
    "Основная идея эрозии похожа только на эрозию почвы, она размывает границы объекта переднего плана (всегда старайтесь, чтобы передний план оставался белым). Так, что это делает? Ядро скользит по изображению (как в **2D**-свертке). Пиксель в исходном изображении ($1$ или $0$) будет считаться $1$, только если все пиксели под ядром равны $1$, в противном случае он размыт (обнуляется).\n",
    "\n",
    "Итак, что происходит, так это то, что все пиксели вблизи границы будут отбрасываться в зависимости от размера ядра. Таким образом, толщина или размер объекта переднего плана уменьшается или просто белая область уменьшается на изображении. Это полезно для удаления небольших белых шумов (как мы видели в главе о цветовом пространстве), отсоединения двух связанных объектов и т. д.\n",
    "\n",
    "Здесь, в качестве примера, я бы использовал полное ядро $5\\times5$. Давайте посмотрим, как это работает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('img/j.png')\n",
    "\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv2.erode(img,kernel,iterations = 1)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(6, 4))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(erosion, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Растягивание\n",
    "Это просто противоположность эрозии. Здесь пиксельный элемент равен «$1$», если хотя бы один пиксель под ядром равен «$1$». Таким образом, увеличивается белая область в изображении или увеличивается размер объекта переднего плана. Обычно в таких случаях, как удаление шума, за эрозией следует расширение. Потому что эрозия удаляет белые шумы, но также уменьшает наш объект. Таким образом, мы расширяем это. Поскольку шум исчез, они не вернутся, но наша площадь объекта увеличивается. Это также полезно при соединении сломанных частей объекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(6, 4))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(dilation, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Открытие\n",
    "Открытие - это просто еще одно название эрозии, за которой следует расширение. Это полезно для удаления шума, как мы объяснили выше. Здесь мы используем функцию **cv2.morphologyEx()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## внесем шум\n",
    "noise_img = img.copy()\n",
    "mask = np.random.randint(0,2,size=noise_img.shape).astype(np.bool)\n",
    "r = np.ones(noise_img.shape) * 255\n",
    "noise_img[mask] = r[mask]\n",
    "\n",
    "opening = cv2.morphologyEx(noise_img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(6, 4))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(opening, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Закрытие\n",
    "Закрытие является обратным открытию, растягивание с последующей эрозией. Это полезно при закрытии небольших отверстий внутри объектов переднего плана или маленьких черных точек на объекте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## внесем шум\n",
    "noise_img = img.copy()\n",
    "mask = np.random.randint(0,2,size=noise_img.shape).astype(np.bool)\n",
    "r = np.zeros(noise_img.shape)\n",
    "noise_img[mask] = r[mask]\n",
    "\n",
    "opening = cv2.morphologyEx(noise_img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(6, 4))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(opening, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Морфологический градиент\n",
    "Это разница между расширением и размыванием изображения.\n",
    "\n",
    "Результат будет выглядеть как контур объекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "fig, m_axs = plt.subplots(1, 2, figsize=(6, 4))\n",
    "ax1, ax2 = m_axs\n",
    "\n",
    "ax1.set_title('Исходное изображение')\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax2.set_title('Результат свертки')\n",
    "ax2.imshow(gradient, cmap='gray');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
